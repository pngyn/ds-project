{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8de9d8f3-d73f-468a-a72a-07b73e496e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ddfd518-ba7c-4cb6-9266-f2a8ad03c030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wals_code</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>glottocode</th>\n",
       "      <th>Name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>genus</th>\n",
       "      <th>family</th>\n",
       "      <th>macroarea</th>\n",
       "      <th>countrycodes</th>\n",
       "      <th>...</th>\n",
       "      <th>130B Cultural Categories of Languages with Identity of 'Finger' and 'Hand'_nan</th>\n",
       "      <th>58B Number of Possessive Nouns_1 None reported</th>\n",
       "      <th>58B Number of Possessive Nouns_2 One</th>\n",
       "      <th>58B Number of Possessive Nouns_3 Two to four</th>\n",
       "      <th>58B Number of Possessive Nouns_nan</th>\n",
       "      <th>79B Suppletion in Imperatives and Hortatives_1 A regular and a suppletive form alternate</th>\n",
       "      <th>79B Suppletion in Imperatives and Hortatives_2 Imperative</th>\n",
       "      <th>79B Suppletion in Imperatives and Hortatives_3 Hortative</th>\n",
       "      <th>79B Suppletion in Imperatives and Hortatives_5 None (= no suppletive imperatives reported in the reference material)</th>\n",
       "      <th>79B Suppletion in Imperatives and Hortatives_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abi</td>\n",
       "      <td>axb</td>\n",
       "      <td>abip1241</td>\n",
       "      <td>Abipón</td>\n",
       "      <td>-29.000000</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>South Guaicuruan</td>\n",
       "      <td>Guaicuruan</td>\n",
       "      <td>South America</td>\n",
       "      <td>AR</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abk</td>\n",
       "      <td>abk</td>\n",
       "      <td>abkh1244</td>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>43.083333</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>Northwest Caucasian</td>\n",
       "      <td>Northwest Caucasian</td>\n",
       "      <td>Eurasia</td>\n",
       "      <td>GE</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aco</td>\n",
       "      <td>kjq</td>\n",
       "      <td>west2632</td>\n",
       "      <td>Acoma</td>\n",
       "      <td>34.916667</td>\n",
       "      <td>-107.583333</td>\n",
       "      <td>Keresan</td>\n",
       "      <td>Keresan</td>\n",
       "      <td>North America</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aeg</td>\n",
       "      <td>arz</td>\n",
       "      <td>egyp1253</td>\n",
       "      <td>Arabic (Egyptian)</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>Semitic</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Africa</td>\n",
       "      <td>EG</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ain</td>\n",
       "      <td>ain</td>\n",
       "      <td>ainu1240</td>\n",
       "      <td>Ainu</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>Ainu</td>\n",
       "      <td>Ainu</td>\n",
       "      <td>Eurasia</td>\n",
       "      <td>JP</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ala</td>\n",
       "      <td>amp</td>\n",
       "      <td>alam1246</td>\n",
       "      <td>Alamblak</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>143.333333</td>\n",
       "      <td>Sepik Hill</td>\n",
       "      <td>Sepik</td>\n",
       "      <td>Papunesia</td>\n",
       "      <td>PG</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ame</td>\n",
       "      <td>aey</td>\n",
       "      <td>amel1241</td>\n",
       "      <td>Amele</td>\n",
       "      <td>-5.250000</td>\n",
       "      <td>145.583333</td>\n",
       "      <td>Madang</td>\n",
       "      <td>Trans-New Guinea</td>\n",
       "      <td>Papunesia</td>\n",
       "      <td>PG</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ana</td>\n",
       "      <td>aro</td>\n",
       "      <td>arao1248</td>\n",
       "      <td>Araona</td>\n",
       "      <td>-12.333333</td>\n",
       "      <td>-67.750000</td>\n",
       "      <td>Tacanan</td>\n",
       "      <td>Tacanan</td>\n",
       "      <td>South America</td>\n",
       "      <td>BO</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>apu</td>\n",
       "      <td>apu</td>\n",
       "      <td>apur1254</td>\n",
       "      <td>Apurinã</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-67.000000</td>\n",
       "      <td>Purus</td>\n",
       "      <td>Arawakan</td>\n",
       "      <td>South America</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arm</td>\n",
       "      <td>hye</td>\n",
       "      <td>nucl1235</td>\n",
       "      <td>Armenian (Eastern)</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>Armenian</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Eurasia</td>\n",
       "      <td>AM</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  wals_code iso_code glottocode                Name   latitude   longitude  \\\n",
       "0       abi      axb   abip1241              Abipón -29.000000  -61.000000   \n",
       "1       abk      abk   abkh1244              Abkhaz  43.083333   41.000000   \n",
       "2       aco      kjq   west2632               Acoma  34.916667 -107.583333   \n",
       "3       aeg      arz   egyp1253   Arabic (Egyptian)  30.000000   31.000000   \n",
       "4       ain      ain   ainu1240                Ainu  43.000000  143.000000   \n",
       "5       ala      amp   alam1246            Alamblak  -4.666667  143.333333   \n",
       "6       ame      aey   amel1241               Amele  -5.250000  145.583333   \n",
       "7       ana      aro   arao1248              Araona -12.333333  -67.750000   \n",
       "8       apu      apu   apur1254             Apurinã  -9.000000  -67.000000   \n",
       "9       arm      hye   nucl1235  Armenian (Eastern)  40.000000   45.000000   \n",
       "\n",
       "                 genus               family      macroarea countrycodes  ...  \\\n",
       "0     South Guaicuruan           Guaicuruan  South America           AR  ...   \n",
       "1  Northwest Caucasian  Northwest Caucasian        Eurasia           GE  ...   \n",
       "2              Keresan              Keresan  North America           US  ...   \n",
       "3              Semitic         Afro-Asiatic         Africa           EG  ...   \n",
       "4                 Ainu                 Ainu        Eurasia           JP  ...   \n",
       "5           Sepik Hill                Sepik      Papunesia           PG  ...   \n",
       "6               Madang     Trans-New Guinea      Papunesia           PG  ...   \n",
       "7              Tacanan              Tacanan  South America           BO  ...   \n",
       "8                Purus             Arawakan  South America           BR  ...   \n",
       "9             Armenian        Indo-European        Eurasia           AM  ...   \n",
       "\n",
       "   130B Cultural Categories of Languages with Identity of 'Finger' and 'Hand'_nan  \\\n",
       "0                                                  1                                \n",
       "1                                                  1                                \n",
       "2                                                  1                                \n",
       "3                                                  1                                \n",
       "4                                                  1                                \n",
       "5                                                  1                                \n",
       "6                                                  1                                \n",
       "7                                                  1                                \n",
       "8                                                  1                                \n",
       "9                                                  1                                \n",
       "\n",
       "   58B Number of Possessive Nouns_1 None reported  \\\n",
       "0                                               0   \n",
       "1                                               1   \n",
       "2                                               1   \n",
       "3                                               1   \n",
       "4                                               1   \n",
       "5                                               1   \n",
       "6                                               1   \n",
       "7                                               0   \n",
       "8                                               1   \n",
       "9                                               1   \n",
       "\n",
       "   58B Number of Possessive Nouns_2 One  \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "2                                     0   \n",
       "3                                     0   \n",
       "4                                     0   \n",
       "5                                     0   \n",
       "6                                     0   \n",
       "7                                     0   \n",
       "8                                     0   \n",
       "9                                     0   \n",
       "\n",
       "   58B Number of Possessive Nouns_3 Two to four  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "5                                             0   \n",
       "6                                             0   \n",
       "7                                             0   \n",
       "8                                             0   \n",
       "9                                             0   \n",
       "\n",
       "   58B Number of Possessive Nouns_nan  \\\n",
       "0                                   1   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "5                                   0   \n",
       "6                                   0   \n",
       "7                                   1   \n",
       "8                                   0   \n",
       "9                                   0   \n",
       "\n",
       "   79B Suppletion in Imperatives and Hortatives_1 A regular and a suppletive form alternate  \\\n",
       "0                                                  0                                          \n",
       "1                                                  0                                          \n",
       "2                                                  0                                          \n",
       "3                                                  0                                          \n",
       "4                                                  0                                          \n",
       "5                                                  0                                          \n",
       "6                                                  0                                          \n",
       "7                                                  0                                          \n",
       "8                                                  0                                          \n",
       "9                                                  0                                          \n",
       "\n",
       "   79B Suppletion in Imperatives and Hortatives_2 Imperative  \\\n",
       "0                                                  0           \n",
       "1                                                  0           \n",
       "2                                                  0           \n",
       "3                                                  1           \n",
       "4                                                  0           \n",
       "5                                                  0           \n",
       "6                                                  0           \n",
       "7                                                  0           \n",
       "8                                                  0           \n",
       "9                                                  1           \n",
       "\n",
       "   79B Suppletion in Imperatives and Hortatives_3 Hortative  \\\n",
       "0                                                  0          \n",
       "1                                                  0          \n",
       "2                                                  1          \n",
       "3                                                  0          \n",
       "4                                                  0          \n",
       "5                                                  0          \n",
       "6                                                  0          \n",
       "7                                                  0          \n",
       "8                                                  0          \n",
       "9                                                  0          \n",
       "\n",
       "   79B Suppletion in Imperatives and Hortatives_5 None (= no suppletive imperatives reported in the reference material)  \\\n",
       "0                                                  0                                                                      \n",
       "1                                                  1                                                                      \n",
       "2                                                  0                                                                      \n",
       "3                                                  0                                                                      \n",
       "4                                                  1                                                                      \n",
       "5                                                  1                                                                      \n",
       "6                                                  1                                                                      \n",
       "7                                                  1                                                                      \n",
       "8                                                  1                                                                      \n",
       "9                                                  0                                                                      \n",
       "\n",
       "   79B Suppletion in Imperatives and Hortatives_nan  \n",
       "0                                                 1  \n",
       "1                                                 0  \n",
       "2                                                 0  \n",
       "3                                                 0  \n",
       "4                                                 0  \n",
       "5                                                 0  \n",
       "6                                                 0  \n",
       "7                                                 0  \n",
       "8                                                 0  \n",
       "9                                                 0  \n",
       "\n",
       "[10 rows x 1187 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading csv file into Pandas. I'm using the 200 language sample for initial exploration, but later on I will use the larger dataset.\n",
    "data = pd.read_csv(\"200-language-sample.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ee27784-72e4-4f4d-ae4a-acf7787dcd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sino-Tibetan</th>\n",
       "      <th>Trans-New Guinea</th>\n",
       "      <th>Indo-European</th>\n",
       "      <th>Niger-Congo</th>\n",
       "      <th>Austronesian</th>\n",
       "      <th>Afro-Asiatic</th>\n",
       "      <th>1A Consonant Inventories_1 Small</th>\n",
       "      <th>1A Consonant Inventories_2 Moderately small</th>\n",
       "      <th>1A Consonant Inventories_3 Average</th>\n",
       "      <th>1A Consonant Inventories_4 Moderately large</th>\n",
       "      <th>...</th>\n",
       "      <th>18A Absence of Common Consonants_3 No fricatives</th>\n",
       "      <th>18A Absence of Common Consonants_4 No nasals</th>\n",
       "      <th>18A Absence of Common Consonants_nan</th>\n",
       "      <th>19A Presence of Uncommon Consonants_1 None</th>\n",
       "      <th>19A Presence of Uncommon Consonants_2 Clicks</th>\n",
       "      <th>19A Presence of Uncommon Consonants_3 Labial-velars</th>\n",
       "      <th>19A Presence of Uncommon Consonants_4 Pharyngeals</th>\n",
       "      <th>19A Presence of Uncommon Consonants_5 'Th' sounds</th>\n",
       "      <th>19A Presence of Uncommon Consonants_7 Pharyngeals and \"th\"</th>\n",
       "      <th>19A Presence of Uncommon Consonants_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.331082</td>\n",
       "      <td>0.363609</td>\n",
       "      <td>0.377874</td>\n",
       "      <td>0.403113</td>\n",
       "      <td>0.424604</td>\n",
       "      <td>0.331082</td>\n",
       "      <td>0.348072</td>\n",
       "      <td>0.363609</td>\n",
       "      <td>0.486352</td>\n",
       "      <td>0.450961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211451</td>\n",
       "      <td>0.465130</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.291712</td>\n",
       "      <td>0.211451</td>\n",
       "      <td>0.312404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sino-Tibetan  Trans-New Guinea  Indo-European  Niger-Congo  \\\n",
       "count     65.000000         65.000000      65.000000    65.000000   \n",
       "mean       0.123077          0.153846       0.169231     0.200000   \n",
       "std        0.331082          0.363609       0.377874     0.403113   \n",
       "min        0.000000          0.000000       0.000000     0.000000   \n",
       "25%        0.000000          0.000000       0.000000     0.000000   \n",
       "50%        0.000000          0.000000       0.000000     0.000000   \n",
       "75%        0.000000          0.000000       0.000000     0.000000   \n",
       "max        1.000000          1.000000       1.000000     1.000000   \n",
       "\n",
       "       Austronesian  Afro-Asiatic  1A Consonant Inventories_1 Small  \\\n",
       "count     65.000000     65.000000                         65.000000   \n",
       "mean       0.230769      0.123077                          0.138462   \n",
       "std        0.424604      0.331082                          0.348072   \n",
       "min        0.000000      0.000000                          0.000000   \n",
       "25%        0.000000      0.000000                          0.000000   \n",
       "50%        0.000000      0.000000                          0.000000   \n",
       "75%        0.000000      0.000000                          0.000000   \n",
       "max        1.000000      1.000000                          1.000000   \n",
       "\n",
       "       1A Consonant Inventories_2 Moderately small  \\\n",
       "count                                    65.000000   \n",
       "mean                                      0.153846   \n",
       "std                                       0.363609   \n",
       "min                                       0.000000   \n",
       "25%                                       0.000000   \n",
       "50%                                       0.000000   \n",
       "75%                                       0.000000   \n",
       "max                                       1.000000   \n",
       "\n",
       "       1A Consonant Inventories_3 Average  \\\n",
       "count                           65.000000   \n",
       "mean                             0.369231   \n",
       "std                              0.486352   \n",
       "min                              0.000000   \n",
       "25%                              0.000000   \n",
       "50%                              0.000000   \n",
       "75%                              1.000000   \n",
       "max                              1.000000   \n",
       "\n",
       "       1A Consonant Inventories_4 Moderately large  ...  \\\n",
       "count                                    65.000000  ...   \n",
       "mean                                      0.276923  ...   \n",
       "std                                       0.450961  ...   \n",
       "min                                       0.000000  ...   \n",
       "25%                                       0.000000  ...   \n",
       "50%                                       0.000000  ...   \n",
       "75%                                       1.000000  ...   \n",
       "max                                       1.000000  ...   \n",
       "\n",
       "       18A Absence of Common Consonants_3 No fricatives  \\\n",
       "count                                         65.000000   \n",
       "mean                                           0.030769   \n",
       "std                                            0.174036   \n",
       "min                                            0.000000   \n",
       "25%                                            0.000000   \n",
       "50%                                            0.000000   \n",
       "75%                                            0.000000   \n",
       "max                                            1.000000   \n",
       "\n",
       "       18A Absence of Common Consonants_4 No nasals  \\\n",
       "count                                          65.0   \n",
       "mean                                            0.0   \n",
       "std                                             0.0   \n",
       "min                                             0.0   \n",
       "25%                                             0.0   \n",
       "50%                                             0.0   \n",
       "75%                                             0.0   \n",
       "max                                             0.0   \n",
       "\n",
       "       18A Absence of Common Consonants_nan  \\\n",
       "count                             65.000000   \n",
       "mean                               0.046154   \n",
       "std                                0.211451   \n",
       "min                                0.000000   \n",
       "25%                                0.000000   \n",
       "50%                                0.000000   \n",
       "75%                                0.000000   \n",
       "max                                1.000000   \n",
       "\n",
       "       19A Presence of Uncommon Consonants_1 None  \\\n",
       "count                                   65.000000   \n",
       "mean                                     0.692308   \n",
       "std                                      0.465130   \n",
       "min                                      0.000000   \n",
       "25%                                      0.000000   \n",
       "50%                                      1.000000   \n",
       "75%                                      1.000000   \n",
       "max                                      1.000000   \n",
       "\n",
       "       19A Presence of Uncommon Consonants_2 Clicks  \\\n",
       "count                                     65.000000   \n",
       "mean                                       0.015385   \n",
       "std                                        0.124035   \n",
       "min                                        0.000000   \n",
       "25%                                        0.000000   \n",
       "50%                                        0.000000   \n",
       "75%                                        0.000000   \n",
       "max                                        1.000000   \n",
       "\n",
       "       19A Presence of Uncommon Consonants_3 Labial-velars  \\\n",
       "count                                          65.000000     \n",
       "mean                                            0.092308     \n",
       "std                                             0.291712     \n",
       "min                                             0.000000     \n",
       "25%                                             0.000000     \n",
       "50%                                             0.000000     \n",
       "75%                                             0.000000     \n",
       "max                                             1.000000     \n",
       "\n",
       "       19A Presence of Uncommon Consonants_4 Pharyngeals  \\\n",
       "count                                          65.000000   \n",
       "mean                                            0.046154   \n",
       "std                                             0.211451   \n",
       "min                                             0.000000   \n",
       "25%                                             0.000000   \n",
       "50%                                             0.000000   \n",
       "75%                                             0.000000   \n",
       "max                                             1.000000   \n",
       "\n",
       "       19A Presence of Uncommon Consonants_5 'Th' sounds  \\\n",
       "count                                          65.000000   \n",
       "mean                                            0.107692   \n",
       "std                                             0.312404   \n",
       "min                                             0.000000   \n",
       "25%                                             0.000000   \n",
       "50%                                             0.000000   \n",
       "75%                                             0.000000   \n",
       "max                                             1.000000   \n",
       "\n",
       "       19A Presence of Uncommon Consonants_7 Pharyngeals and \"th\"  \\\n",
       "count                                               65.0            \n",
       "mean                                                 0.0            \n",
       "std                                                  0.0            \n",
       "min                                                  0.0            \n",
       "25%                                                  0.0            \n",
       "50%                                                  0.0            \n",
       "75%                                                  0.0            \n",
       "max                                                  0.0            \n",
       "\n",
       "       19A Presence of Uncommon Consonants_nan  \n",
       "count                                65.000000  \n",
       "mean                                  0.046154  \n",
       "std                                   0.211451  \n",
       "min                                   0.000000  \n",
       "25%                                   0.000000  \n",
       "50%                                   0.000000  \n",
       "75%                                   0.000000  \n",
       "max                                   1.000000  \n",
       "\n",
       "[8 rows x 113 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What are the largest families in the dataset?\n",
    "families = data.groupby(by=\"family\")\n",
    "families.size().sort_values()\n",
    "\n",
    "#For now, I'm just going to focus on the largest language families and their phonologies. \n",
    "\n",
    "largest_families = ['Sino-Tibetan',\n",
    "                  'Trans-New Guinea',\n",
    "                  'Indo-European',\n",
    "                  'Niger-Congo',\n",
    "                  'Austronesian',\n",
    "                  'Afro-Asiatic'] \n",
    "\n",
    "data = data.loc[data['family'].isin(largest_families)]\n",
    "\n",
    "phonological_features = ['1A Consonant Inventories_1 Small',\n",
    " '1A Consonant Inventories_2 Moderately small',\n",
    " '1A Consonant Inventories_3 Average',\n",
    " '1A Consonant Inventories_4 Moderately large',\n",
    " '1A Consonant Inventories_5 Large',\n",
    " '1A Consonant Inventories_nan',\n",
    " '2A Vowel Quality Inventories_1 Small (2-4)',\n",
    " '2A Vowel Quality Inventories_2 Average (5-6)',\n",
    " '2A Vowel Quality Inventories_3 Large (7-14)',\n",
    " '2A Vowel Quality Inventories_nan',\n",
    " '3A Consonant-Vowel Ratio_1 Low',\n",
    " '3A Consonant-Vowel Ratio_2 Moderately low',\n",
    " '3A Consonant-Vowel Ratio_3 Average',\n",
    " '3A Consonant-Vowel Ratio_4 Moderately high',\n",
    " '3A Consonant-Vowel Ratio_5 High',\n",
    " '3A Consonant-Vowel Ratio_nan',\n",
    " '4A Voicing in Plosives and Fricatives_1 No voicing contrast',\n",
    " '4A Voicing in Plosives and Fricatives_2 In plosives alone',\n",
    " '4A Voicing in Plosives and Fricatives_3 In fricatives alone',\n",
    " '4A Voicing in Plosives and Fricatives_4 In both plosives and fricatives',\n",
    " '4A Voicing in Plosives and Fricatives_nan',\n",
    " '5A Voicing and Gaps in Plosive Systems_1 Other',\n",
    " '5A Voicing and Gaps in Plosive Systems_2 None missing in /p t k b d g/',\n",
    " '5A Voicing and Gaps in Plosive Systems_3 Missing /p/',\n",
    " '5A Voicing and Gaps in Plosive Systems_4 Missing /g/',\n",
    " '5A Voicing and Gaps in Plosive Systems_5 Both missing',\n",
    " '5A Voicing and Gaps in Plosive Systems_nan',\n",
    " '6A Uvular Consonants_1 None',\n",
    " '6A Uvular Consonants_2 Uvular stops only',\n",
    " '6A Uvular Consonants_3 Uvular continuants only',\n",
    " '6A Uvular Consonants_4 Uvular stops and continuants',\n",
    " '6A Uvular Consonants_nan',\n",
    " '7A Glottalized Consonants_1 No glottalized consonants',\n",
    " '7A Glottalized Consonants_2 Ejectives only',\n",
    " '7A Glottalized Consonants_3 Implosives only',\n",
    " '7A Glottalized Consonants_4 Glottalized resonants only',\n",
    " '7A Glottalized Consonants_5 Ejectives and implosives',\n",
    " '7A Glottalized Consonants_6 Ejectives and glottalized resonants',\n",
    " '7A Glottalized Consonants_7 Implosives and glottalized resonants',\n",
    " '7A Glottalized Consonants_nan',\n",
    " '8A Lateral Consonants_1 No laterals',\n",
    " '8A Lateral Consonants_2 /l/, no obstruent laterals',\n",
    " '8A Lateral Consonants_3 Laterals, but no /l/, no obstruent laterals',\n",
    " '8A Lateral Consonants_4 /l/ and lateral obstruent',\n",
    " '8A Lateral Consonants_5 No /l/, but lateral obstruents',\n",
    " '8A Lateral Consonants_nan',\n",
    " '9A The Velar Nasal_1 Initial velar nasal',\n",
    " '9A The Velar Nasal_2 No initial velar nasal',\n",
    " '9A The Velar Nasal_3 No velar nasal',\n",
    " '9A The Velar Nasal_nan',\n",
    " '10A Vowel Nasalization_1 Contrast present',\n",
    " '10A Vowel Nasalization_2 Contrast absent',\n",
    " '10A Vowel Nasalization_nan',\n",
    " '11A Front Rounded Vowels_1 None',\n",
    " '11A Front Rounded Vowels_2 High and mid',\n",
    " '11A Front Rounded Vowels_3 High only',\n",
    " '11A Front Rounded Vowels_4 Mid only',\n",
    " '11A Front Rounded Vowels_nan',\n",
    " '12A Syllable Structure_1 Simple',\n",
    " '12A Syllable Structure_2 Moderately complex',\n",
    " '12A Syllable Structure_3 Complex',\n",
    " '12A Syllable Structure_nan',\n",
    " '13A Tone_1 No tones',\n",
    " '13A Tone_2 Simple tone system',\n",
    " '13A Tone_3 Complex tone system',\n",
    " '13A Tone_nan',\n",
    " '14A Fixed Stress Locations_1 No fixed stress',\n",
    " '14A Fixed Stress Locations_2 Initial',\n",
    " '14A Fixed Stress Locations_3 Second',\n",
    " '14A Fixed Stress Locations_5 Antepenultimate',\n",
    " '14A Fixed Stress Locations_6 Penultimate',\n",
    " '14A Fixed Stress Locations_7 Ultimate',\n",
    " '14A Fixed Stress Locations_nan',\n",
    " '15A Weight-Sensitive Stress_1 Left-edge: First or second',\n",
    " '15A Weight-Sensitive Stress_3 Right-edge: Ultimate or penultimate',\n",
    " '15A Weight-Sensitive Stress_4 Right-oriented: One of the last three',\n",
    " '15A Weight-Sensitive Stress_5 Unbounded: Stress can be anywhere',\n",
    " '15A Weight-Sensitive Stress_6 Combined: Right-edge and unbounded',\n",
    " '15A Weight-Sensitive Stress_7 Not predictable',\n",
    " '15A Weight-Sensitive Stress_8 Fixed stress (no weight-sensitivity)',\n",
    " '15A Weight-Sensitive Stress_nan',\n",
    " '16A Weight Factors in Weight-Sensitive Stress Systems_1 No weight',\n",
    " '16A Weight Factors in Weight-Sensitive Stress Systems_2 Long vowel',\n",
    " '16A Weight Factors in Weight-Sensitive Stress Systems_3 Coda consonant',\n",
    " '16A Weight Factors in Weight-Sensitive Stress Systems_4 Long vowel or coda consonant',\n",
    " '16A Weight Factors in Weight-Sensitive Stress Systems_5 Prominence',\n",
    " '16A Weight Factors in Weight-Sensitive Stress Systems_6 Lexical stress',\n",
    " '16A Weight Factors in Weight-Sensitive Stress Systems_7 Combined',\n",
    " '16A Weight Factors in Weight-Sensitive Stress Systems_nan',\n",
    " '17A Rhythm Types_1 Trochaic',\n",
    " '17A Rhythm Types_2 Iambic',\n",
    " '17A Rhythm Types_3 Dual: both trochaic and iambic',\n",
    " '17A Rhythm Types_4 Undetermined',\n",
    " '17A Rhythm Types_5 No rhythmic stress',\n",
    " '17A Rhythm Types_nan',\n",
    " '18A Absence of Common Consonants_1 All present',\n",
    " '18A Absence of Common Consonants_2 No bilabials',\n",
    " '18A Absence of Common Consonants_3 No fricatives',\n",
    " '18A Absence of Common Consonants_4 No nasals',\n",
    " '18A Absence of Common Consonants_nan',\n",
    " '19A Presence of Uncommon Consonants_1 None',\n",
    " '19A Presence of Uncommon Consonants_2 Clicks',\n",
    " '19A Presence of Uncommon Consonants_3 Labial-velars',\n",
    " '19A Presence of Uncommon Consonants_4 Pharyngeals',\n",
    " \"19A Presence of Uncommon Consonants_5 'Th' sounds\",\n",
    " '19A Presence of Uncommon Consonants_7 Pharyngeals and \"th\"',\n",
    " '19A Presence of Uncommon Consonants_nan']\n",
    "\n",
    "phonology = pd.concat([data[large_families],data[phonological_features],data['Name']],axis=1)\n",
    "\n",
    "phonology.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca85b48f-f4a4-4c81-99cb-cc43656fe020",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonology_feature_names = phonology.iloc[:, np.arange(6,113)].columns.to_list()\n",
    "phonology_features = phonology.iloc[:, np.arange(6,113)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5183c3af-957c-45cb-8268-d795b0bd0b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth:  1  accuracy:  0.8769230769230769\n",
      "max depth:  2  accuracy:  0.8769230769230769\n",
      "max depth:  3  accuracy:  0.9230769230769231\n",
      "max depth:  4  accuracy:  0.9846153846153847\n",
      "max depth:  5  accuracy:  1.0\n",
      "max depth:  6  accuracy:  1.0\n",
      "max depth:  7  accuracy:  1.0\n",
      "max depth:  8  accuracy:  1.0\n",
      "max depth:  9  accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#As we increase max depth, how does the accuracy of the classifier chance? Let's start with Indo-European.\n",
    "\n",
    "for i in np.arange(1,10):\n",
    "    decisionTree = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    decisionTree = decisionTree.fit(phonology_features, phonology['Indo-European'])\n",
    "    y_pred = decisionTree.predict(phonology_features)\n",
    "    print(\"max depth: \",i,\" accuracy: \",metrics.accuracy_score(y_true = phonology['Indo-European'], y_pred = y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65993611-e627-4553-9be5-95f5423ab617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth:  1  accuracy:  0.8769230769230769\n",
      "max depth:  2  accuracy:  0.9076923076923077\n",
      "max depth:  3  accuracy:  0.9538461538461539\n",
      "max depth:  4  accuracy:  1.0\n",
      "max depth:  5  accuracy:  1.0\n",
      "max depth:  6  accuracy:  1.0\n",
      "max depth:  7  accuracy:  1.0\n",
      "max depth:  8  accuracy:  1.0\n",
      "max depth:  9  accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Sino Tibetan\n",
    "\n",
    "for i in np.arange(1,10):\n",
    "    decisionTree = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    decisionTree = decisionTree.fit(phonology_features, phonology['Sino-Tibetan'])\n",
    "    y_pred = decisionTree.predict(phonology_features)\n",
    "    print(\"max depth: \",i,\" accuracy: \",metrics.accuracy_score(y_true = phonology['Sino-Tibetan'], y_pred = y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "48672645-e3cc-4a8b-80fe-f0cfa766a587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth:  1  accuracy:  0.7692307692307693\n",
      "max depth:  2  accuracy:  0.9384615384615385\n",
      "max depth:  3  accuracy:  0.9538461538461539\n",
      "max depth:  4  accuracy:  0.9846153846153847\n",
      "max depth:  5  accuracy:  1.0\n",
      "max depth:  6  accuracy:  1.0\n",
      "max depth:  7  accuracy:  1.0\n",
      "max depth:  8  accuracy:  1.0\n",
      "max depth:  9  accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Austronesian\n",
    "\n",
    "for i in np.arange(1,10):\n",
    "    decisionTree = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    decisionTree = decisionTree.fit(phonology_features, phonology['Austronesian'])\n",
    "    y_pred = decisionTree.predict(phonology_features)\n",
    "    print(\"max depth: \",i,\" accuracy: \",metrics.accuracy_score(y_true = phonology['Austronesian'], y_pred = y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a240644f-f123-4846-b5f9-a2838988d4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9230769230769231\n",
      "|--- 6A Uvular Consonants_3 Uvular continuants only <= 0.50\n",
      "|   |--- 12A Syllable Structure_3 Complex <= 0.50\n",
      "|   |   |--- 4A Voicing in Plosives and Fricatives_nan <= 0.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- 4A Voicing in Plosives and Fricatives_nan >  0.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |--- 12A Syllable Structure_3 Complex >  0.50\n",
      "|   |   |--- 9A The Velar Nasal_1 Initial velar nasal <= 0.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- 9A The Velar Nasal_1 Initial velar nasal >  0.50\n",
      "|   |   |   |--- class: 0\n",
      "|--- 6A Uvular Consonants_3 Uvular continuants only >  0.50\n",
      "|   |--- class: 1\n",
      "\n",
      "misclassified: Arabic (Egyptian) \n",
      "   true family:  Afro-Asiatic\n",
      "misclassified: Beja \n",
      "   true family:  Afro-Asiatic\n",
      "misclassified: Berber (Middle Atlas) \n",
      "   true family:  Afro-Asiatic\n",
      "misclassified: Irish \n",
      "   true family:  Indo-European\n",
      "misclassified: Spanish \n",
      "   true family:  Indo-European\n"
     ]
    }
   ],
   "source": [
    "#Now let's make a decision tree, starting again with Indo-European using a max depth of 3\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "decisionTree = decisionTree.fit(phonology.iloc[:, np.arange(6,113)], phonology['Indo-European'])\n",
    "\n",
    "y_pred = decisionTree.predict(phonology.iloc[:, np.arange(6,113)])\n",
    "\n",
    "print(metrics.accuracy_score(y_true = phonology['Indo-European'], y_pred = y_pred))\n",
    "\n",
    "#Printing the tree\n",
    "print(tree.export_text(decisionTree, feature_names = phonology_feature_names))\n",
    "\n",
    "#Printing which languages were misclassified\n",
    "for i in np.arange(len(phonology)):\n",
    "    a = decisionTree.predict(phonology.iloc[:, np.arange(6,113)])[i]\n",
    "    language_name = phonology['Name'].to_list()[i]\n",
    "    True_value = phonology['Indo-European'].to_list()[i]\n",
    "    True_data = data.loc[data['Name'] == language_name][['Name','family','countrycodes','genus','macroarea']]\n",
    "    if True_value != a:\n",
    "        print(\"misclassified:\",language_name, \"\\n   true family: \", True_data['family'].to_string(index=False))\n",
    "    #if True_value == a:\n",
    "        #print(\"correctly classified:\",language_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97eb99c-f33b-4576-acbf-34bc5c6d9ed7",
   "metadata": {},
   "source": [
    "According to this model, if a language has only continuant uvual consonants, it is Indo-European.\n",
    "If not, but it has a complex syllable structure and no initial velar nasal, it is also Indo-European. \n",
    "Otherwise, it's not Indo-European.\n",
    "\n",
    "With the larger dataset, I expect uvual continuants will not be so important.\n",
    "\n",
    "Spanish was misclassified because its syllable structure is only moderately complex. \n",
    "\n",
    "All three misclassified non-IE languages were Afroasiatic: Egyptian Arabic, Beja, and Berber. Beja is a language of Sudan with a complex syllable structure that lacks uvualar consonants and velar nasals. Berber is a language of 🇲🇦 which is similarly misclassified.\n",
    "\n",
    "Why might this be?\n",
    "\n",
    "How about Austronesian?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "63d2569e-61c0-4188-9b1b-377892f4a9dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692307692307693\n",
      "|--- 9A The Velar Nasal_1 Initial velar nasal <= 0.50\n",
      "|   |--- class: 0\n",
      "|--- 9A The Velar Nasal_1 Initial velar nasal >  0.50\n",
      "|   |--- class: 0\n",
      "\n",
      "misclassified: Batak (Karo) \n",
      "   true family:  Austronesian\n",
      "misclassified: Chamorro \n",
      "   true family:  Austronesian\n",
      "misclassified: Drehu \n",
      "   true family:  Austronesian\n",
      "misclassified: Fijian \n",
      "   true family:  Austronesian\n",
      "misclassified: Indonesian \n",
      "   true family:  Austronesian\n",
      "misclassified: Kilivila \n",
      "   true family:  Austronesian\n",
      "misclassified: Kiribati \n",
      "   true family:  Austronesian\n",
      "misclassified: Malagasy \n",
      "   true family:  Austronesian\n",
      "misclassified: Maori \n",
      "   true family:  Austronesian\n",
      "misclassified: Paiwan \n",
      "   true family:  Austronesian\n",
      "misclassified: Paamese \n",
      "   true family:  Austronesian\n",
      "misclassified: Rapanui \n",
      "   true family:  Austronesian\n",
      "misclassified: Taba \n",
      "   true family:  Austronesian\n",
      "misclassified: Tagalog \n",
      "   true family:  Austronesian\n",
      "misclassified: Tukang Besi \n",
      "   true family:  Austronesian\n"
     ]
    }
   ],
   "source": [
    "decisionTree = tree.DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "decisionTree = decisionTree.fit(phonology.iloc[:, np.arange(6,113)], phonology['Austronesian'])\n",
    "\n",
    "y_pred = decisionTree.predict(phonology.iloc[:, np.arange(6,113)])\n",
    "\n",
    "print(metrics.accuracy_score(y_true = phonology['Austronesian'], y_pred = y_pred))\n",
    "\n",
    "print(tree.export_text(decisionTree, feature_names = phonology_feature_names))\n",
    "\n",
    "for i in np.arange(len(phonology)):\n",
    "    a = decisionTree.predict(phonology.iloc[:, np.arange(6,113)])[i]\n",
    "    language_name = phonology['Name'].to_list()[i]\n",
    "    True_value = phonology['Austronesian'].to_list()[i]\n",
    "    True_data = data.loc[data['Name'] == language_name][['Name','family','countrycodes','genus','macroarea']]\n",
    "    if True_value != a:\n",
    "        print(\"misclassified:\",language_name, \"\\n   true family: \", True_data['family'].to_string(index=False))\n",
    "    #if True_value == a:\n",
    "        #print(\"correctly classified:\",language_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "228576fb-93ea-4ce7-a05e-692348a50cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9384615384615385\n",
      "|--- 1A Consonant Inventories_1 Small <= 0.50\n",
      "|   |--- 5A Voicing and Gaps in Plosive Systems_5 Both missing <= 0.50\n",
      "|   |   |--- class: 0\n",
      "|   |--- 5A Voicing and Gaps in Plosive Systems_5 Both missing >  0.50\n",
      "|   |   |--- class: 1\n",
      "|--- 1A Consonant Inventories_1 Small >  0.50\n",
      "|   |--- 9A The Velar Nasal_1 Initial velar nasal <= 0.50\n",
      "|   |   |--- class: 1\n",
      "|   |--- 9A The Velar Nasal_1 Initial velar nasal >  0.50\n",
      "|   |   |--- class: 0\n",
      "\n",
      "misclassified: Amele \n",
      "   true family:  Trans-New Guinea\n",
      "misclassified: Hamtai \n",
      "   true family:  Trans-New Guinea\n",
      "misclassified: Kewa \n",
      "   true family:  Trans-New Guinea\n",
      "misclassified: Kobon \n",
      "   true family:  Trans-New Guinea\n"
     ]
    }
   ],
   "source": [
    "#Trans New Guinean?\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "decisionTree = decisionTree.fit(phonology.iloc[:, np.arange(6,113)], phonology['Trans-New Guinea'])\n",
    "\n",
    "y_pred = decisionTree.predict(phonology.iloc[:, np.arange(6,113)])\n",
    "\n",
    "print(metrics.accuracy_score(y_true = phonology['Trans-New Guinea'], y_pred = y_pred))\n",
    "\n",
    "print(tree.export_text(decisionTree, feature_names = phonology_feature_names))\n",
    "\n",
    "for i in np.arange(len(phonology)):\n",
    "    a = decisionTree.predict(phonology.iloc[:, np.arange(6,113)])[i]\n",
    "    language_name = phonology['Name'].to_list()[i]\n",
    "    True_value = phonology['Trans-New Guinea'].to_list()[i]\n",
    "    True_data = data.loc[data['Name'] == language_name][['Name','family','countrycodes','genus','macroarea']]\n",
    "    if True_value != a:\n",
    "        print(\"misclassified:\",language_name, \"\\n   true family: \", True_data['family'].to_string(index=False))\n",
    "    #if True_value == a:\n",
    "        #print(\"correctly classified:\",language_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
